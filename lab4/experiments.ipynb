{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 4: RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.RNN' from '/Users/annasanchezespunyes/Documents/GitHub/DD2424/lab4/src/RNN.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src import RNN \n",
    "from src import preprocessing \n",
    "import importlib\n",
    "import numpy as np\n",
    "importlib.reload(preprocessing)\n",
    "importlib.reload(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data = preprocessing.load_data(\"/Users/annasanchezespunyes/Documents/GitHub/DD2424/lab4/data/goblet_book.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'char', 'K', 'char_to_ind', 'ind_to_char'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 25\n",
    "data = read_data['data']\n",
    "\n",
    "input_chars = data[0:sequence_length]\n",
    "target_chars = data[1: 1 + sequence_length]\n",
    "X = RNN.encode(input_chars, read_data['char_to_ind'])\n",
    "Y = RNN.encode(target_chars, read_data['char_to_ind'])\n",
    "\n",
    "model = RNN.RNN(read_data['K'])\n",
    "grads,_ = model.compute_gradients(X, Y)\n",
    "grads['W'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = np.zeros(shape=(5,1))\n",
    "model_num = RNN.RNN(read_data['K'])\n",
    "grad_num = model_num.ComputeGradsNum(X,Y,h0,1e-4)\n",
    "grad_num['W'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:18<00:00, 27.76s/it]\n"
     ]
    }
   ],
   "source": [
    "model_num = RNN.RNN(read_data['K'])\n",
    "grad_num = model_num.compute_grads_num(X,Y,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_matrices(a_anal,a_num):\n",
    "    assert a_anal.shape == a_num.shape\n",
    "    matrix = np.abs(a_anal - a_num)\n",
    "    print(\"Value maximum\", matrix.max())\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value maximum 0.0015772632395394553\n",
      "HEllo\n"
     ]
    }
   ],
   "source": [
    "check_matrices(grad_num['W'],grads['W'])\n",
    "print(\"HEllo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0 loss = 109.55066526768358\n",
      "iter = 100 loss = 120.5727403487124\n",
      "iter = 200 loss = 131.87182102017638\n",
      "iter = 300 loss = 143.84329489233738\n",
      "iter = 400 loss = 155.3850845495284\n",
      "iter = 500 loss = 169.04278941139958\n",
      "iter = 600 loss = 181.5907723774956\n",
      "iter = 700 loss = 193.1438301989236\n",
      "iter = 800 loss = 202.42266900264457\n",
      "iter = 900 loss = 213.63340329727524\n",
      "iter = 1000 loss = 223.1946236725861\n",
      "iter = 1100 loss = 229.95004633368706\n",
      "iter = 1200 loss = 238.73221641819242\n",
      "iter = 1300 loss = 244.84684718576682\n",
      "iter = 1400 loss = 251.11939376198393\n",
      "iter = 1500 loss = 254.8054759202429\n",
      "iter = 1600 loss = 257.8470633257868\n",
      "iter = 1700 loss = 259.3560884912915\n",
      "iter = 1800 loss = 262.97980491332544\n",
      "iter = 1900 loss = 264.76538025833185\n",
      "iter = 2000 loss = 264.00885322332016\n",
      "iter = 2100 loss = 263.7622104479511\n",
      "iter = 2200 loss = 264.49891180366234\n",
      "iter = 2300 loss = 266.1826678494691\n",
      "iter = 2400 loss = 266.63338179541205\n",
      "iter = 2500 loss = 267.51230538496503\n",
      "iter = 2600 loss = 271.46012600768574\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-ef4f199e03ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/DD2424/lab4/src/RNN.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, read_data, sequence_length, learning_rate)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'char_to_ind'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'char_to_ind'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/DD2424/lab4/src/RNN.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, input_labels, target_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/DD2424/lab4/src/RNN.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, input_labels, target_labels, p_list, h_list, sequence_length, a_list)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'U'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_wrt_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_wrt_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_wrt_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model = RNN.RNN(read_data['K'])\n",
    "train_model.fit(read_data,sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(character_index, number_distinct_characters):\n",
    "    character_one_hot = np.zeros(shape=(number_distinct_characters,1))\n",
    "    character_one_hot[character_index,0] = 1\n",
    "    \n",
    "    return character_one_hot\n",
    "\n",
    "class RNN2(object):\n",
    "    \n",
    "    def __init__(self, k, m=5, sig=0.01, seed=42):\n",
    "        self.k = k\n",
    "        self.m = m\n",
    "        self.ind_to_char = None\n",
    "        self.char_to_ind = None\n",
    "        self.param = {'U': np.random.normal(0, sig, size=(m, k)), 'V': np.random.normal(0, sig, size=(k, m)),\n",
    "                      'W': np.random.normal(0, sig, size=(m, m)), 'b': np.zeros((m, 1)),\n",
    "                      'c': np.zeros((k, 1))}\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    def forward(self, input_labels, h0):\n",
    "        seq_length = input_labels.shape[1]\n",
    "        p, h, a = [], [h0], []\n",
    "        for t in range(seq_length):\n",
    "            a.append(self.param['W']@h[-1]+self.param['U']@input_labels[:,[t]]+self.param['b'])\n",
    "            h.append(np.tanh(a[t]))\n",
    "            p.append(self.softmax(self.param['V']@h[-1]+self.param['c']))\n",
    "        return p,h, a\n",
    "\n",
    "    def calculate_loss(self,Y,p):\n",
    "        loss = 0\n",
    "        for t in range(len(p)):\n",
    "            loss -= np.log(Y[:,[t]].T@p[t])[0,0]\n",
    "        return loss\n",
    "    \n",
    "    def blank_parameters(self):\n",
    "        return {'U': np.zeros(self.param['U'].shape), 'V': np.zeros(self.param['V'].shape),\n",
    "                'W': np.zeros(self.param['W'].shape), 'b': np.zeros(self.param['b'].shape),\n",
    "                'c': np.zeros(self.param['c'].shape)}\n",
    "    \n",
    "    def backward(self, X, Y, p, h, a):\n",
    "        seq_length = X.shape[1]\n",
    "        h0 = h[0]\n",
    "        h = h[1:]\n",
    "        grads = self.blank_parameters()\n",
    "        grad_a = [None]*seq_length\n",
    "        \n",
    "         \n",
    "        for t in range((seq_length-1),-1,-1):\n",
    "            g = -(Y[:,[t]]-p[t]).T\n",
    "            grads['V'] += g.T@h[t].T\n",
    "            grads['c'] += g.T\n",
    "            if t<(seq_length-1):\n",
    "                dL_h = g@self.param['V']+grad_a[t+1]@self.param['W']\n",
    "            else:\n",
    "                dL_h = g@self.param['V']\n",
    "            grad_a[t] = (dL_h@np.diag(1-np.square(h[t][:,0])))\n",
    "            if t==0:\n",
    "                grads['W'] += grad_a[t].T@h0.T\n",
    "            else:\n",
    "                grads['W'] += grad_a[t].T@h[t-1].T\n",
    "            grads['U'] += grad_a[t].T@X[:,[t]].T\n",
    "            grads['b'] += grad_a[t].T\n",
    "\n",
    "        # Clipping gradients\n",
    "        for parameter in ['b','c','U','W','V']:\n",
    "            grads[parameter] = np.clip(grads[parameter], -5, 5)\n",
    "\n",
    "        return grads   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(input_text, char_to_ind):\n",
    "    indices = [char_to_ind[char] for char in input_text]\n",
    "    one_hot_encoding = (np.eye(len(char_to_ind.keys()))[indices]).T\n",
    "    return one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 80\n",
    "m = 5\n",
    "myRNN = RNN2(read_data['K'])\n",
    "sequence_length = 25\n",
    "data = read_data['data']\n",
    "\n",
    "input_chars = data[0:sequence_length]\n",
    "target_chars = data[1: 1 + sequence_length]\n",
    "X = encode(input_chars, read_data['char_to_ind'])\n",
    "Y = encode(target_chars, read_data['char_to_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HW\n",
      "Loss is 109.55059417856833\n"
     ]
    }
   ],
   "source": [
    "h0 = np.zeros(shape=(m,1))\n",
    "print(\"HW\")\n",
    "p, h, a = myRNN.forward(X,h0)\n",
    "#loss = myRNN.calculate_loss(Y,p)\n",
    "loss = myRNN.calculate_loss(Y,p)\n",
    "print(\"Loss is\", loss)\n",
    "newGRADS = myRNN.backward(X, Y, p, h, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def ComputeGradsNum(RNN, X, Y, h0, h=1e-4):\n",
    "   \n",
    "    # Iterate parameters and compute gradients numerically\n",
    "    \n",
    "    GRADS = RNN.blank_parameters()\n",
    "    for parameter in RNN.param.keys():\n",
    "        for i in range(RNN.param[parameter].shape[0]):\n",
    "            for j in range(RNN.param[parameter].shape[1]):\n",
    "                RNN_try = copy.deepcopy(RNN)\n",
    "                RNN_try.param[parameter][i,j] += h\n",
    "                p, _, _ = RNN_try.forward(X, h0)\n",
    "                loss2 = RNN_try.calculate_loss(Y,p)\n",
    "                RNN_try.param[parameter][i,j] -= 2*h\n",
    "                p, _, _ = RNN_try.forward(X, h0)\n",
    "                loss1 = RNN_try.calculate_loss(Y,p)\n",
    "                GRADS[parameter][i,j] = (loss2-loss1)/(2*h)\n",
    "    \n",
    "    return GRADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "newGRADS_num = ComputeGradsNum(myRNN, X, Y, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For b, the % of absolute errors <1e-6 is 100.0 and the maximum is 7.796818191074806e-10\n",
      "For c, the % of absolute errors <1e-6 is 100.0 and the maximum is 8.039172660900817e-10\n",
      "For U, the % of absolute errors <1e-6 is 100.0 and the maximum is 2.733765765844387e-10\n",
      "For W, the % of absolute errors <1e-6 is 100.0 and the maximum is 2.42241289527545e-10\n",
      "For V, the % of absolute errors <1e-6 is 100.0 and the maximum is 3.3293381755932633e-10\n"
     ]
    }
   ],
   "source": [
    "for parameter in ['b','c','U','W','V']:\n",
    "    error = abs(newGRADS_num[parameter]-newGRADS[parameter])\n",
    "    mean_error = np.mean(error<1e-6)\n",
    "    max_error = error.max()\n",
    "    print('For '+parameter+', the % of absolute errors <1e-6 is '+str(mean_error*100)+ \\\n",
    "          ' and the maximum is '+str(max_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 3: k-layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.classifier as cls\n",
    "import data.layer as layer\n",
    "from data.load_data import *\n",
    "from src.utils import *\n",
    "import importlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_data', 'validation_data', 'test_data'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data()\n",
    "data = preprocessing(data)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Upgrade assigment 2 and test k-layer net-works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradients of a 2-layer network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a 2-layer network that calculates gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"importlib.reload(cls)\\nlayers = 2\\ninput_nodes = len(data['train_data']['data'][:, :10])\\nhidden_nodes = 10\\noutput_nodes = len(data['train_data']['one_hot'])\\n\\n\\nclassifier = cls.Classifier()\\nclassifier.add_layer(n=hidden_nodes, input_nodes=input_nodes)\\nclassifier.add_layer(n=output_nodes,input_nodes=hidden_nodes)\\n\\npredictions = classifier.predict(data['train_data']['data'],complete=True)\\nassert len(predictions) == layers + 1 #this should be number of layers + 1\\ngrad_w,grad_b = classifier.compute_gradients(data['train_data']['data'][:, :20],\\n                                               data['train_data']['one_hot'][:, :20],lambda_reg=0,eta=0.1)\\n\\nclassifier2 = cls.Classifier()\\nclassifier2.add_layer(n=hidden_nodes, input_nodes=input_nodes)\\nclassifier2.add_layer(n=output_nodes,input_nodes=hidden_nodes)\\ngrad_w_num,grad_b_num = classifier2.check_gradients_num(data['train_data']['data'][:, :20],\\n                                          data['train_data']['one_hot'][:, :20],\\n                                            1e-6)\\nfor l in range(len(grad_w)):\\n    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_w[l], grad_w_num[l]))\\n    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_b[l], grad_b_num[l]))\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"importlib.reload(cls)\n",
    "layers = 2\n",
    "input_nodes = len(data['train_data']['data'][:, :10])\n",
    "hidden_nodes = 10\n",
    "output_nodes = len(data['train_data']['one_hot'])\n",
    "\n",
    "\n",
    "classifier = cls.Classifier()\n",
    "classifier.add_layer(n=hidden_nodes, input_nodes=input_nodes)\n",
    "classifier.add_layer(n=output_nodes,input_nodes=hidden_nodes)\n",
    "\n",
    "predictions = classifier.predict(data['train_data']['data'],complete=True)\n",
    "assert len(predictions) == layers + 1 #this should be number of layers + 1\n",
    "grad_w,grad_b = classifier.compute_gradients(data['train_data']['data'][:, :20],\n",
    "                                               data['train_data']['one_hot'][:, :20],lambda_reg=0,eta=0.1)\n",
    "\n",
    "classifier2 = cls.Classifier()\n",
    "classifier2.add_layer(n=hidden_nodes, input_nodes=input_nodes)\n",
    "classifier2.add_layer(n=output_nodes,input_nodes=hidden_nodes)\n",
    "grad_w_num,grad_b_num = classifier2.check_gradients_num(data['train_data']['data'][:, :20],\n",
    "                                          data['train_data']['one_hot'][:, :20],\n",
    "                                            1e-6)\n",
    "for l in range(len(grad_w)):\n",
    "    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_w[l], grad_w_num[l]))\n",
    "    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_b[l], grad_b_num[l]))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradients of a 3-layer network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a 3-layer network that calculates gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"importlib.reload(cls)\\nlayers = 3\\ninput_nodes = len(data['train_data']['data'][:, :10])\\nhidden_nodes1 = 10\\nhidden_nodes2 = 8\\noutput_nodes = len(data['train_data']['one_hot'])\\n\\nclassifier = cls.Classifier()\\nclassifier.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\\nclassifier.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\\nclassifier.add_layer(n=output_nodes,input_nodes=hidden_nodes2)\\n\\npredictions = classifier.predict(data['train_data']['data'],complete=True)\\nassert len(predictions) == layers + 1 #this should be number of layers + 1\\ngrad_w,grad_b  = classifier.compute_gradients(data['train_data']['data'][:, :20],\\n                                               data['train_data']['one_hot'][:, :20],lambda_reg=0,eta=0.1)\\n\\nclassifier2 = cls.Classifier()\\nclassifier2.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\\nclassifier2.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\\nclassifier2.add_layer(n=output_nodes,input_nodes=hidden_nodes2)\\n\\ngrad_w_num,grad_b_num = classifier2.check_gradients_num(data['train_data']['data'][:, :20],\\n                                          data['train_data']['one_hot'][:, :20],\\n                                            1e-6)\\n                                      \\nfor l in range(len(grad_w)):\\n    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_w[l], grad_w_num[l]))\\n    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_b[l], grad_b_num[l]))\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"importlib.reload(cls)\n",
    "layers = 3\n",
    "input_nodes = len(data['train_data']['data'][:, :10])\n",
    "hidden_nodes1 = 10\n",
    "hidden_nodes2 = 8\n",
    "output_nodes = len(data['train_data']['one_hot'])\n",
    "\n",
    "classifier = cls.Classifier()\n",
    "classifier.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\n",
    "classifier.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\n",
    "classifier.add_layer(n=output_nodes,input_nodes=hidden_nodes2)\n",
    "\n",
    "predictions = classifier.predict(data['train_data']['data'],complete=True)\n",
    "assert len(predictions) == layers + 1 #this should be number of layers + 1\n",
    "grad_w,grad_b  = classifier.compute_gradients(data['train_data']['data'][:, :20],\n",
    "                                               data['train_data']['one_hot'][:, :20],lambda_reg=0,eta=0.1)\n",
    "\n",
    "classifier2 = cls.Classifier()\n",
    "classifier2.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\n",
    "classifier2.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\n",
    "classifier2.add_layer(n=output_nodes,input_nodes=hidden_nodes2)\n",
    "\n",
    "grad_w_num,grad_b_num = classifier2.check_gradients_num(data['train_data']['data'][:, :20],\n",
    "                                          data['train_data']['one_hot'][:, :20],\n",
    "                                            1e-6)\n",
    "                                      \n",
    "for l in range(len(grad_w)):\n",
    "    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_w[l], grad_w_num[l]))\n",
    "    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_b[l], grad_b_num[l]))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradients of a 4-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"importlib.reload(cls)\\nlayers = 4\\ninput_nodes = len(data['train_data']['data'][:, :10])\\nhidden_nodes1 = 10\\nhidden_nodes2 = 8\\nhidden_nodes3 = 11\\noutput_nodes = len(data['train_data']['one_hot'])\\n\\nclassifier = cls.Classifier()\\nclassifier.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\\nclassifier.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\\nclassifier.add_layer(n=hidden_nodes3, input_nodes=hidden_nodes2)\\nclassifier.add_layer(n=output_nodes,input_nodes=hidden_nodes3)\\n\\npredictions = classifier.predict(data['train_data']['data'],complete=True)\\nassert len(predictions) == layers + 1 #this should be number of layers + 1\\nparameters = classifier.compute_gradients(data['train_data']['data'][:, :20],\\n                                               data['train_data']['one_hot'][:, :20],lambda_reg=0,eta=0.1)\\n\\nclassifier2 = cls.Classifier()\\nclassifier2.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\\nclassifier2.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\\nclassifier2.add_layer(n=hidden_nodes3, input_nodes=hidden_nodes2)\\nclassifier2.add_layer(n=output_nodes,input_nodes=hidden_nodes3)\\n\\nW,b = classifier2.check_gradients_num(data['train_data']['data'][:, :20],\\n                                          data['train_data']['one_hot'][:, :20],\\n                                            1e-6)\\n                                      \\nfor l in range(len(grad_w)):\\n    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_w[l], grad_w_num[l]))\\n    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_b[l], grad_b_num[l]))\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"importlib.reload(cls)\n",
    "layers = 4\n",
    "input_nodes = len(data['train_data']['data'][:, :10])\n",
    "hidden_nodes1 = 10\n",
    "hidden_nodes2 = 8\n",
    "hidden_nodes3 = 11\n",
    "output_nodes = len(data['train_data']['one_hot'])\n",
    "\n",
    "classifier = cls.Classifier()\n",
    "classifier.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\n",
    "classifier.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\n",
    "classifier.add_layer(n=hidden_nodes3, input_nodes=hidden_nodes2)\n",
    "classifier.add_layer(n=output_nodes,input_nodes=hidden_nodes3)\n",
    "\n",
    "predictions = classifier.predict(data['train_data']['data'],complete=True)\n",
    "assert len(predictions) == layers + 1 #this should be number of layers + 1\n",
    "parameters = classifier.compute_gradients(data['train_data']['data'][:, :20],\n",
    "                                               data['train_data']['one_hot'][:, :20],lambda_reg=0,eta=0.1)\n",
    "\n",
    "classifier2 = cls.Classifier()\n",
    "classifier2.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\n",
    "classifier2.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\n",
    "classifier2.add_layer(n=hidden_nodes3, input_nodes=hidden_nodes2)\n",
    "classifier2.add_layer(n=output_nodes,input_nodes=hidden_nodes3)\n",
    "\n",
    "W,b = classifier2.check_gradients_num(data['train_data']['data'][:, :20],\n",
    "                                          data['train_data']['one_hot'][:, :20],\n",
    "                                            1e-6)\n",
    "                                      \n",
    "for l in range(len(grad_w)):\n",
    "    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_w[l], grad_w_num[l]))\n",
    "    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_b[l], grad_b_num[l]))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Can I train multi-layer networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a 2-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'importlib.reload(cls)\\ndata = load_no_validation()\\ndata = preprocessing(data)\\n\\nlayers = 2\\ninput_nodes = len(data[\\'train_data\\'][\\'data\\'])\\nhidden_nodes = 50\\noutput_nodes = len(data[\\'train_data\\'][\\'one_hot\\'])\\n\\nn_batch = 90\\ncycles = 3\\nn_s = 1000\\nn = len(data[\\'train_data\\'][\\'data\\'][0])\\nepochs = int(cycles*n_s*2/(n/n_batch))\\n\\nclassifier = cls.Classifier()\\nclassifier.add_layer(n=hidden_nodes, input_nodes=input_nodes)\\nclassifier.add_layer(n=output_nodes,input_nodes=hidden_nodes)\\nmetrics = classifier.fit(data[\\'train_data\\'][\\'data\\'], data[\\'train_data\\'][\\'one_hot\\'],\\n                         data[\\'validation_data\\'][\\'data\\'], data[\\'validation_data\\'][\\'one_hot\\'],\\n                         data[\\'train_data\\'][\\'labels\\'],\\n                         data[\\'validation_data\\'][\\'labels\\'],\\n                         \\'cross-entropy\\',\\n                         n_batch=n_batch, eta=1e-5, n_epochs=epochs, lamda=0.0009, eta_min=1e-5, eta_max=1e-1, n_s=n_s)\\n\\nerror_plot_normal(metrics[\\'accuracy_train\\'], metrics[\\'accuracy_val\\'], \"Accuracy\")\\nerror_plot_normal(metrics[\\'loss_train\\'], metrics[\\'loss_val\\'], \"Loss\")\\nprediction_test = classifier.predict(data[\\'test_data\\'][\\'data\\'])\\ntest_accuracy = classifier.compute_accuracy(data[\\'test_data\\'][\\'labels\\'],prediction_test)\\nprint(\"Test accuracy:\" ,test_accuracy)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"importlib.reload(cls)\n",
    "data = load_no_validation()\n",
    "data = preprocessing(data)\n",
    "\n",
    "layers = 2\n",
    "input_nodes = len(data['train_data']['data'])\n",
    "hidden_nodes = 50\n",
    "output_nodes = len(data['train_data']['one_hot'])\n",
    "\n",
    "n_batch = 90\n",
    "cycles = 3\n",
    "n_s = 1000\n",
    "n = len(data['train_data']['data'][0])\n",
    "epochs = int(cycles*n_s*2/(n/n_batch))\n",
    "\n",
    "classifier = cls.Classifier()\n",
    "classifier.add_layer(n=hidden_nodes, input_nodes=input_nodes)\n",
    "classifier.add_layer(n=output_nodes,input_nodes=hidden_nodes)\n",
    "metrics = classifier.fit(data['train_data']['data'], data['train_data']['one_hot'],\n",
    "                         data['validation_data']['data'], data['validation_data']['one_hot'],\n",
    "                         data['train_data']['labels'],\n",
    "                         data['validation_data']['labels'],\n",
    "                         'cross-entropy',\n",
    "                         n_batch=n_batch, eta=1e-5, n_epochs=epochs, lamda=0.0009, eta_min=1e-5, eta_max=1e-1, n_s=n_s)\n",
    "\n",
    "error_plot_normal(metrics['accuracy_train'], metrics['accuracy_val'], \"Accuracy\")\n",
    "error_plot_normal(metrics['loss_train'], metrics['loss_val'], \"Loss\")\n",
    "prediction_test = classifier.predict(data['test_data']['data'])\n",
    "test_accuracy = classifier.compute_accuracy(data['test_data']['labels'],prediction_test)\n",
    "print(\"Test accuracy:\" ,test_accuracy)\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a 3-layer network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added: Xavier initialization +Random shuffling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'importlib.reload(cls)\\nlayers = 3\\ninput_nodes = len(data[\\'train_data\\'][\\'data\\'])\\nhidden_nodes1 = 50\\nhidden_nodes2 = 50\\noutput_nodes = len(data[\\'train_data\\'][\\'one_hot\\'])\\n\\nn_batch = 100\\ncycles = 2\\nn_s = 5*49000/n_batch\\nn = len(data[\\'train_data\\'][\\'data\\'][0])\\nepochs = int(cycles*n_s*2/(n/n_batch))\\nlamda = 0.005\\n\\nclassifier = cls.Classifier()\\nclassifier.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\\nclassifier.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\\nclassifier.add_layer(n=output_nodes,input_nodes=hidden_nodes2)\\nmetrics = classifier.fit(data[\\'train_data\\'][\\'data\\'], data[\\'train_data\\'][\\'one_hot\\'],\\n                         data[\\'validation_data\\'][\\'data\\'], data[\\'validation_data\\'][\\'one_hot\\'],\\n                         data[\\'train_data\\'][\\'labels\\'],\\n                         data[\\'validation_data\\'][\\'labels\\'],\\n                         \\'cross-entropy\\',\\n                         n_batch=n_batch, eta=1e-5, n_epochs=epochs, lamda=lamda, eta_min=1e-5, eta_max=1e-1, n_s=n_s)\\nerror_plot_normal(metrics[\\'accuracy_train\\'], metrics[\\'accuracy_val\\'], \"Accuracy\")\\nerror_plot_normal(metrics[\\'loss_train\\'], metrics[\\'loss_val\\'], \"Loss\")\\nprediction_test = classifier.predict(data[\\'test_data\\'][\\'data\\'])\\ntest_accuracy = classifier.compute_accuracy(data[\\'test_data\\'][\\'labels\\'],prediction_test)\\nprint(\"Test accuracy:\" ,test_accuracy)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"importlib.reload(cls)\n",
    "layers = 3\n",
    "input_nodes = len(data['train_data']['data'])\n",
    "hidden_nodes1 = 50\n",
    "hidden_nodes2 = 50\n",
    "output_nodes = len(data['train_data']['one_hot'])\n",
    "\n",
    "n_batch = 100\n",
    "cycles = 2\n",
    "n_s = 5*49000/n_batch\n",
    "n = len(data['train_data']['data'][0])\n",
    "epochs = int(cycles*n_s*2/(n/n_batch))\n",
    "lamda = 0.005\n",
    "\n",
    "classifier = cls.Classifier()\n",
    "classifier.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\n",
    "classifier.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\n",
    "classifier.add_layer(n=output_nodes,input_nodes=hidden_nodes2)\n",
    "metrics = classifier.fit(data['train_data']['data'], data['train_data']['one_hot'],\n",
    "                         data['validation_data']['data'], data['validation_data']['one_hot'],\n",
    "                         data['train_data']['labels'],\n",
    "                         data['validation_data']['labels'],\n",
    "                         'cross-entropy',\n",
    "                         n_batch=n_batch, eta=1e-5, n_epochs=epochs, lamda=lamda, eta_min=1e-5, eta_max=1e-1, n_s=n_s)\n",
    "error_plot_normal(metrics['accuracy_train'], metrics['accuracy_val'], \"Accuracy\")\n",
    "error_plot_normal(metrics['loss_train'], metrics['loss_val'], \"Loss\")\n",
    "prediction_test = classifier.predict(data['test_data']['data'])\n",
    "test_accuracy = classifier.compute_accuracy(data['test_data']['labels'],prediction_test)\n",
    "print(\"Test accuracy:\" ,test_accuracy)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a 9-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'importlib.reload(cls)\\nlayers = 3\\ninput_nodes = len(data[\\'train_data\\'][\\'data\\'])\\noutput_nodes = len(data[\\'train_data\\'][\\'one_hot\\'])\\nnodes = [input_nodes, 50, 30, 20, 20, 10, 10, 10, 10, output_nodes]\\nn_batch = 100\\ncycles = 2\\nn_s = 5*49000/n_batch\\nn = len(data[\\'train_data\\'][\\'data\\'][0])\\nepochs = int(cycles*n_s*2/(n/n_batch))\\nlamda = 0.005\\n\\nclassifier = cls.Classifier()\\nfor i in range(len(nodes)-1):\\n    classifier.add_layer(n=nodes[i+1], input_nodes=nodes[i])\\n\\nmetrics = classifier.fit(data[\\'train_data\\'][\\'data\\'], data[\\'train_data\\'][\\'one_hot\\'],\\n                         data[\\'validation_data\\'][\\'data\\'], data[\\'validation_data\\'][\\'one_hot\\'],\\n                         data[\\'train_data\\'][\\'labels\\'],\\n                         data[\\'validation_data\\'][\\'labels\\'],\\n                         \\'cross-entropy\\',\\n                         n_batch=n_batch, eta=1e-5, n_epochs=epochs, lamda=lamda, eta_min=1e-5, eta_max=1e-1, n_s=n_s)\\nerror_plot_normal(metrics[\\'accuracy_train\\'], metrics[\\'accuracy_val\\'], \"Accuracy\")\\nerror_plot_normal(metrics[\\'loss_train\\'], metrics[\\'loss_val\\'], \"Loss\")\\nprediction_test = classifier.predict(data[\\'test_data\\'][\\'data\\'])\\ntest_accuracy = classifier.compute_accuracy(data[\\'test_data\\'][\\'labels\\'],prediction_test)\\nprint(\"Test accuracy:\" ,test_accuracy)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"importlib.reload(cls)\n",
    "layers = 3\n",
    "input_nodes = len(data['train_data']['data'])\n",
    "output_nodes = len(data['train_data']['one_hot'])\n",
    "nodes = [input_nodes, 50, 30, 20, 20, 10, 10, 10, 10, output_nodes]\n",
    "n_batch = 100\n",
    "cycles = 2\n",
    "n_s = 5*49000/n_batch\n",
    "n = len(data['train_data']['data'][0])\n",
    "epochs = int(cycles*n_s*2/(n/n_batch))\n",
    "lamda = 0.005\n",
    "\n",
    "classifier = cls.Classifier()\n",
    "for i in range(len(nodes)-1):\n",
    "    classifier.add_layer(n=nodes[i+1], input_nodes=nodes[i])\n",
    "\n",
    "metrics = classifier.fit(data['train_data']['data'], data['train_data']['one_hot'],\n",
    "                         data['validation_data']['data'], data['validation_data']['one_hot'],\n",
    "                         data['train_data']['labels'],\n",
    "                         data['validation_data']['labels'],\n",
    "                         'cross-entropy',\n",
    "                         n_batch=n_batch, eta=1e-5, n_epochs=epochs, lamda=lamda, eta_min=1e-5, eta_max=1e-1, n_s=n_s)\n",
    "error_plot_normal(metrics['accuracy_train'], metrics['accuracy_val'], \"Accuracy\")\n",
    "error_plot_normal(metrics['loss_train'], metrics['loss_val'], \"Loss\")\n",
    "prediction_test = classifier.predict(data['test_data']['data'])\n",
    "test_accuracy = classifier.compute_accuracy(data['test_data']['labels'],prediction_test)\n",
    "print(\"Test accuracy:\" ,test_accuracy)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Batch Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cls)\n",
    "importlib.reload(layer)\n",
    "data = load_no_validation()\n",
    "data = preprocessing(data)\n",
    "\n",
    "layers = 2\n",
    "input_nodes = len(data['train_data']['data'])\n",
    "hidden_nodes = 50\n",
    "output_nodes = len(data['train_data']['one_hot'])\n",
    "\n",
    "n_batch = 90\n",
    "cycles = 3\n",
    "n_s = 1000\n",
    "n = len(data['train_data']['data'][0])\n",
    "epochs = int(cycles*n_s*2/(n/n_batch))\n",
    "\n",
    "classifier = cls.Classifier()\n",
    "classifier.add_layer(n=hidden_nodes, input_nodes=input_nodes)\n",
    "classifier.add_layer(n=output_nodes,input_nodes=hidden_nodes)\n",
    "prediction = classifier.predict(data['train_data']['data'],complete=False,batch_normalization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 49000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_data']['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data.layer' from '/Users/annasanchezespunyes/Documents/GitHub/DD2424/lab3/data/layer.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cls)\n",
    "importlib.reload(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST layer (10, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grad_w,grad_b,grad_gamma,grad_beta = classifier.compute_gradients(data['train_data']['data'][:, :20],\n",
    "                                               data['train_data']['one_hot'][:, :20],lambda_reg=0,eta=0.1,batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"classifier2 = cls.Classifier()\\nclassifier2.add_layer(n=hidden_nodes, input_nodes=input_nodes)\\nclassifier2.add_layer(n=output_nodes,input_nodes=hidden_nodes)\\nW_grads, b_grads, gamma_grads, beta_grads = classifier2.check_gradients_num_batch(data['train_data']['data'][:, :20],\\n                                          data['train_data']['one_hot'][:, :20],\\n                                            1e-6)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"classifier2 = cls.Classifier()\n",
    "classifier2.add_layer(n=hidden_nodes, input_nodes=input_nodes)\n",
    "classifier2.add_layer(n=output_nodes,input_nodes=hidden_nodes)\n",
    "W_grads, b_grads, gamma_grads, beta_grads = classifier2.check_gradients_num_batch(data['train_data']['data'][:, :20],\n",
    "                                          data['train_data']['one_hot'][:, :20],\n",
    "                                            1e-6)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for l in range(len(grad_w)):\\n    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_w[l], W_grads[l]))\\n    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_b[l], b_grads[l]))\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for l in range(len(grad_w)):\n",
    "    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_w[l], W_grads[l]))\n",
    "    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_b[l], b_grads[l]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for l in range(len(grad_gamma)):\\n    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_gamma[l], gamma_grads[l]))\\n    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_beta[l], beta_grads[l]))\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for l in range(len(grad_gamma)):\n",
    "    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_gamma[l], gamma_grads[l]))\n",
    "    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_beta[l], beta_grads[l]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST layer (10, 8)\n"
     ]
    }
   ],
   "source": [
    "layers = 3\n",
    "input_nodes = len(data['train_data']['data'][:, :10])\n",
    "hidden_nodes1 = 11\n",
    "hidden_nodes2 = 8\n",
    "output_nodes = len(data['train_data']['one_hot'])\n",
    "\n",
    "classifier = cls.Classifier()\n",
    "classifier.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\n",
    "classifier.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\n",
    "classifier.add_layer(n=output_nodes,input_nodes=hidden_nodes2)\n",
    "\n",
    "\n",
    "grad_w,grad_b,grad_gamma,grad_beta  = classifier.compute_gradients(data['train_data']['data'][:, :20],\n",
    "                                               data['train_data']['one_hot'][:, :20],lambda_reg=0,eta=0.1,batch_norm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing numerical gradients... Layer  1\n",
      "Computing numerical gradients... Layer  2\n",
      "Computing numerical gradients... Layer  3\n"
     ]
    }
   ],
   "source": [
    "classifier2 = cls.Classifier()\n",
    "classifier2.add_layer(n=hidden_nodes1, input_nodes=input_nodes)\n",
    "classifier2.add_layer(n=hidden_nodes2, input_nodes=hidden_nodes1)\n",
    "classifier2.add_layer(n=output_nodes,input_nodes=hidden_nodes2)\n",
    "\n",
    "W_grads, b_grads, gamma_grads, beta_grads= classifier2.check_gradients_num_batch(data['train_data']['data'][:, :20],\n",
    "                                          data['train_data']['one_hot'][:, :20],\n",
    "                                            1e-6)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_w1 well calculated:  8.676674069984722e-10\n",
      "gradient_b1 well calculated:  4.4408921262562017e-10\n",
      "gradient_w2 well calculated:  4.5376321450296686e-10\n",
      "gradient_b2 well calculated:  2.2204463545616447e-10\n",
      "gradient_w3 well calculated:  5.862805050466102e-10\n",
      "gradient_b3 well calculated:  6.1579250032473e-10\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(grad_w)):\n",
    "    print(f'gradient_w{l+1} well calculated: ', check_matrices(grad_w[l], W_grads[l]))\n",
    "    print(f'gradient_b{l+1} well calculated: ', check_matrices(grad_b[l], b_grads[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_w[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_grads[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.862805050466102e-10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_matrices(grad_w[2], W_grads[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
